---
title: "80 20 code"
date: 2017-12-25
categories:
---

It is easy to build quick and dirty software.  It is more challenging to build better software w/o huge investments of time & money.  To use a cliche phrase how do we accomplish 80% of what we need with 20% of the effort?  

* TOC
{:toc}

### Integrating w APIs

Here is a common task.  User registers and a week later we send a follow up email.  To do that we create a background process.

{% highlight ruby %}
# app/jobs/
class FollowupEmailJob < ApplicationJob
  def perform
    User.where('created_at ...').each do |user|
      MyMailer.followup(user).deliver_now
    end
  end
end
# app/mailers/
class MyMailer < ApplicationMailer
  def followup user
    @first_name = user.first_name
    mail to: user.email
  end
end
{% endhighlight %}

Email content will be in  `app/views/my_mailer/followup.html.erb`.  This code is easy to write using default functionality provided by Ruby on Rails.  The problem comes with scale because we are sending emails one at a time.  That creates a long running process which could crash and then it will restart at the beginning sending duplicate emails.  

Long term solution is to leverage rich API functionality provided by services such as Sendgrid or Mailchimp.  Since most of the content in the email message is the same we can build a template in the Sendgrid UI and pass array of parameters `[{email: .., first_name: ...}, ...]`.  This code will be much faster, more reliable and consume less network IO.  It will also take more time to write and test.  For example, we will need to implement batching functionality passing arrays of X users at a time.  

How can we improve our original design w/o investing a lot of expensive engineering time?  One of the problems is a single long running process.  [ActionMailer](http://guides.rubyonrails.org/action_mailer_basics.html) supports `deliver_later` which throws each email in the queue.   Then multiple workers process these jobs but each job is only 1 email.  We can even stop our workers and the messages will be persisted in the queue.  We would need to use a queue such as AWS SQS or Sidekiq with Redis to queue the jobs VERY quickly which will allow `FollowupEmailJob` to finish right away.

{% highlight ruby %}
class FollowupEmailJob < ApplicationJob
  def perform
    Usere.where(...).select(:email, :first_name).each do |user|
      MyMailer.followup(user.email, user.first_name).deliver_later
    end
  end
end
class MyMailer < ApplicationMailer
  def followup user_email, user_first_name
    @first_name = user_first_name
    mail to: user_email
  end
end
{% endhighlight %}

We also modified our code to pass `user_email` and `user_first_name` directly instead of passing User object.  That is because we cannot store complex object in the queue.  Ruby on Rails will automatically use [globalid](https://github.com/rails/globalid) to enqueue but that will cause lots of requests for individual user records when actually processing jobs.  We also modified our query to only select `first_name` and `email` from the DB.  

This is not a perfect solution as it will still make Sendgrid API call for every email we need to send.  But now we will be doing those in parallel.  And it only required us to change a few lines of code.  

The example above is very simple but how can we apply the same pattern to more complex software problems?  The challenge is that when we are first building software we do not know all the requirements.  Some of the initial features might need to be removed.  So change will be inevitable.  

The reason it was fairly easy for us to make the modifications above is because our code was very modular.  There was clear separation between the background job that determined which users need to be emailed to, the mailer code that actually made SMTP calls and the template with content.  We could have done these changes in phases with first introducing a queue, then updating mailer to use `deliver_later` and last modifying the code to pass email and first_name directly.  

### Make small changes gradually  


{% highlight ruby %}

{% endhighlight %}

### Data integrity

Another area where we can achieve big long term return for small early investment is ensuring data integrity.  What if we are building a CMS where articles go through basic workflow process:  `draft - submitted - approved`.  Alternatively article can be `rejected` which moves it from `submitted` back to `draft` status.  Quick and dirty way is create string `status` field on Article model.  In the UI we have a dropdown with list of status values.  Then in our `ArticlesController` we do `Article.update(status: 'approved')`.  But how do we ensure that only users with appropriate permissions can perform the actions?  Author can submit article but only Publisher can approve it.  

A better and only slightly more time consuming approach is to define workflow with something like [state machine](https://github.com/aasm/aasm).  

{% highlight ruby %}
class Article < ApplicationRecord
  include AASM
  aasm do
    state :draft, :initial => true
    state :submitted, :approved, :rejected
    event :submit do
      transitions :from => :draft, :to => :submitted
    end
    event :approve do
      transitions :from => :submitted, :to => :approved
    end
    event :reject do
      transitions :from => :submitted, :to => :draft
    end  
  end
end
{% endhighlight %}

Now we have ability to filter records with automatically created scoped `Article.approved`.  We can also check if a specific article can be approved with `article.may_approve?`.  With a callback we can easily send a notification to author when his/her article is approved.  In our UI we display buttons to `APPROVE` or `REJECT` instead of a dropdown.  Our logic moved from template layer to model which is easier to test.  And we can enforce enumeration on the list of possible values saved as `status` either at model or DB layer preventing someone from accidentally putting article in invalid status.  
